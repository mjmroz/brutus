name: Tests

on:
  push:
    branches: [ master, main, develop ]
  pull_request:
    branches: [ master, main ]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ["3.9", "3.10", "3.11", "3.12"]
        # Note: Python 3.8 dropped (EOL October 2024)
        # Note: Windows is not supported due to healpy dependency
        # Windows users should use WSL (see README)

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        # Install numpy first and lock the version to prevent binary incompatibility
        pip install "numpy>=1.19,<2.0"
        # Install all packages with compiled extensions against this numpy
        # Use --no-build-isolation to ensure they all use the same numpy
        pip install --no-build-isolation "scipy>=1.6.0"
        pip install --no-build-isolation "healpy>=1.14.0"
        # Now install package (which may include astropy, h5py, etc.)
        pip install --no-build-isolation -e ".[test]"

    - name: Cache test data files
      uses: actions/cache@v3
      id: cache-data
      with:
        path: |
          ~/.cache/astro-brutus/
          ~/Library/Caches/astro-brutus/
        key: brutus-data-v2-${{ runner.os }}
        restore-keys: |
          brutus-data-v2-

    - name: Download/Verify test data files
      # IMPORTANT: Always run verification, even if cache hit
      # This ensures files actually exist and weren't corrupted/partially cached
      # The fetch_* functions are smart - they only download if files are missing
      run: |
        # Download essential data files for testing (or verify they exist)
        # GitHub Actions cache limit: 10 GB per repo
        # MIST grids: ~2-4 GB, Isochrones: ~100 MB, Tracks: ~200 MB
        python -c "
        import sys
        import traceback

        try:
            from brutus.data import (
                fetch_grids, fetch_isos, fetch_tracks, fetch_nns,
                fetch_dustmaps, fetch_offsets
            )
            import os
            import pooch

            print('=' * 60)
            print('Verifying/Downloading MIST data files for testing...')
            print('=' * 60)

            # Show cache directory
            cache_dir = pooch.os_cache('astro-brutus')
            print(f'Cache directory: {cache_dir}')
            if os.path.exists(cache_dir):
                files = os.listdir(cache_dir)
                print(f'Existing files in cache: {len(files)} files')
                if files:
                    for f in sorted(files)[:10]:  # Show first 10
                        size = os.path.getsize(os.path.join(cache_dir, f)) / (1024*1024)
                        print(f'  - {f} ({size:.1f} MB)')

            # Create data directory for symlinks
            data_dir = 'data/DATAFILES'
            os.makedirs(data_dir, exist_ok=True)
            print(f'Created/verified directory: {data_dir}')

            print('\n1. Verifying/Downloading MIST grids (~2-3 GB)...')
            path = fetch_grids(grid='mist_v9', target_dir=data_dir)
            print(f'   ✓ MIST grids available at: {path}')
            # Verify the file/symlink exists
            if os.path.exists(path):
                if os.path.islink(path):
                    target = os.readlink(path)
                    print(f'   → Symlink points to: {target}')
                    print(f'   → Target exists: {os.path.exists(target)}')
                else:
                    size_gb = os.path.getsize(path) / (1024*1024*1024)
                    print(f'   → Direct file, size: {size_gb:.2f} GB')
            else:
                print(f'   ⚠ WARNING: File not found at {path}!')

            print('\n2. Verifying/Downloading isochrones (~100 MB)...')
            path = fetch_isos(target_dir=data_dir)
            print(f'   ✓ Isochrones available at: {path}')

            print('\n3. Verifying/Downloading EEP tracks (~200 MB)...')
            path = fetch_tracks(target_dir=data_dir)
            print(f'   ✓ EEP tracks available at: {path}')

            print('\n4. Verifying/Downloading neural network (~1 MB)...')
            path = fetch_nns(target_dir=data_dir)
            print(f'   ✓ Neural network available at: {path}')

            print('\n5. Verifying/Downloading dust maps (~100 MB)...')
            try:
                path = fetch_dustmaps(target_dir=data_dir)
                print(f'   ✓ Dust maps available at: {path}')
            except Exception as e:
                print(f'   ⚠ Dust maps download failed (optional): {e}')

            print('\n6. Verifying/Downloading photometric offsets...')
            try:
                path = fetch_offsets(grid='mist_v9', target_dir=data_dir)
                print(f'   ✓ Offsets available (v9) at: {path}')
            except Exception as e:
                print(f'   ⚠ Offsets download failed (optional): {e}')

            print('\n' + '=' * 60)
            print('All data files verified/downloaded successfully!')

            # Final cache status
            print('\nFinal cache status:')
            if os.path.exists(cache_dir):
                files = os.listdir(cache_dir)
                total_size = sum(os.path.getsize(os.path.join(cache_dir, f))
                                for f in files) / (1024*1024*1024)
                print(f'Total files in cache: {len(files)}')
                print(f'Total cache size: {total_size:.2f} GB')

            # Show what's actually in data/DATAFILES
            print('\nFiles in data/DATAFILES:')
            if os.path.exists(data_dir):
                data_files = os.listdir(data_dir)
                print(f'Total files: {len(data_files)}')
                for f in sorted(data_files):
                    fpath = os.path.join(data_dir, f)
                    if os.path.islink(fpath):
                        target = os.readlink(fpath)
                        exists = 'OK' if os.path.exists(fpath) else 'BROKEN'
                        print(f'  - {f} -> {os.path.basename(target)} [{exists}]')
                    else:
                        size_mb = os.path.getsize(fpath) / (1024*1024)
                        print(f'  - {f} ({size_mb:.1f} MB)')
            else:
                print(f'WARNING: {data_dir} does not exist!')

            print('=' * 60)

        except Exception as e:
            print('\n' + '!' * 60)
            print('ERROR: Could not download data files')
            print('!' * 60)
            print(f'Error: {e}')
            traceback.print_exc()
            print('\nData files are required for tests.')
            print('!' * 60)
            sys.exit(1)  # Fail the workflow if data download fails
        "

    - name: Lint with flake8
      run: |
        # Install flake8 if it's not in test dependencies
        pip install flake8
        # Stop the build if there are Python syntax errors or undefined names
        flake8 src/brutus --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings. Line length is handled by black.
        flake8 src/brutus --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics

    - name: Test with pytest
      env:
        NUMBA_DISABLE_JIT: 1
      run: |
        pytest tests/ -v --cov=brutus --cov-report=xml

    - name: Upload coverage reports to Codecov
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.9'
      uses: codecov/codecov-action@v5
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  lint:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.9"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Check formatting with black
      run: |
        black --check --diff src/brutus tests/

    - name: Check import sorting with isort
      run: |
        isort --check-only --diff src/brutus tests/

    # Type checking is currently optional - mypy has many false positives
    # with scientific Python code (numpy, scipy, etc.)
    # - name: Type checking with mypy
    #   run: |
    #     mypy src/brutus --ignore-missing-imports
    #   continue-on-error: true

  build:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.9"

    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine

    - name: Build package
      run: |
        python -m build

    - name: Check package with twine
      run: |
        twine check dist/*

    - name: Test install from wheel
      run: |
        pip install dist/*.whl
        python -c "import brutus; print(brutus.__version__)"
